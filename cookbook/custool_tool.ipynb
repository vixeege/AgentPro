{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyxnkWVzhqOi"
      },
      "source": [
        "# 🤖 AgentPro Quick Start Guide\n",
        "\n",
        "This notebook will walk you through how to set up and use [AgentPro](https://github.com/traversaal-ai/AgentPro) — a production-ready open-source agent framework built by [Traversaal.ai](https://traversaal.ai) for building powerful, modular, and multi-functional AI agents.\n",
        "\n",
        "### What is AgentPro?\n",
        "AgentPro lets you build intelligent agents that can:\n",
        "- Use language models (like OpenAI’s GPT) as reasoning engines\n",
        "- Solve real-world tasks such as research, automation, and knowledge retrieval\n",
        "- Scale up with custom tools, memory, and orchestration features\n",
        "\n",
        "Whether you're a developer, researcher, or AI enthusiast — this guide will help you:\n",
        "- Build and integrate your own tools with AgentPro\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fi5Eth4ge70O"
      },
      "source": [
        "## Step 1: Clone AgentPro and Install Dependencies\n",
        "\n",
        "To get started with **AgentPro**, begin by cloning the official GitHub repository and installing its dependencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCGHQVf-Q2Zj",
        "outputId": "0d96e6ba-716a-4f08-a6f5-99f969a99a39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m647.0/647.0 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.8/472.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.4/169.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for agentpro (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/traversaal-ai/AgentPro.git -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLfWC5m9fUpT"
      },
      "source": [
        "## Step 2: Set Your API Key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vlEmkaNgjwm"
      },
      "source": [
        "To use OpenAI models with AgentPro, you’ll need an API key from OpenAI. Follow these steps:\n",
        "\n",
        "1. Go to the [OpenAI API platform](https://platform.openai.com/)\n",
        "2. Log in or create an account\n",
        "3. Click \"Create new secret key\"\n",
        "4. Copy the generated key and paste it into the notebook like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "4tV4Qe1RUGcI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your openai API key  is: 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\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "# Load variables from .env file\n",
        "load_dotenv()\n",
        "\n",
        "os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "print(f\"Your openai API key  is: {os.getenv(\"OPENAI_API_KEY\")}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMFP4v5zZmlW"
      },
      "source": [
        "## Step 3: Create a Custom Tool\n",
        "AgentPro is designed to be extensible — you can easily define your own tools for domain-specific tasks.\n",
        "\n",
        "Below is an example of a **custom tool** that queries the Hugging Face Hub and returns the **most downloaded model** for a given task:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_wgIOdcWEYP",
        "outputId": "a22d66dc-f55b-4c0c-8b9f-94877a33aa82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "microsoft/deberta-large-mnli\n"
          ]
        }
      ],
      "source": [
        "from huggingface_hub import list_models\n",
        "\n",
        "# Define the task you're interested in\n",
        "task_name = \"text-classification\"\n",
        "\n",
        "# Get the most downloaded model for the specified task\n",
        "models = list_models(filter=task_name, sort=\"downloads\", direction=-1)\n",
        "top_model = next(iter(models))\n",
        "\n",
        "# Print the model ID\n",
        "print(top_model.id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zbn0sZDqZwyX"
      },
      "source": [
        "## Step 4: Define your tool using AgentPro Tool class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zFrDw_enVAcq"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import os\n",
        "from agentpro import ReactAgent\n",
        "from agentpro.tools import Tool\n",
        "from huggingface_hub import list_models\n",
        "from typing import Any\n",
        "from agentpro import create_model\n",
        "\n",
        "class MostModelTool(Tool):\n",
        "    name: str = \"Most Downloaded Model Finder\" # Human-readable tool name\n",
        "    description: str = \"Finds the most downloaded model for a given task on Hugging Face.\" # Brief explanation of tool for agent\n",
        "    action_type: str = \"find_top_model\" # Use lowercase letters with underscores for agent; avoid spaces, digits and special characters\n",
        "    input_format: str = \"Task name as a string. Example: 'text-classification'\" # Expected input dtype with example\n",
        "\n",
        "    def run(self, input_text: Any) -> str:\n",
        "        task_name = input_text.strip()\n",
        "        models = list_models(filter=task_name, sort=\"downloads\", direction=-1)\n",
        "        top_model = next(models)\n",
        "        return top_model.id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "# custom_tools/course_tool.py\n",
        "\n",
        "from agentpro.tools import Tool\n",
        "from typing import Any\n",
        "from agentpro.model import OpenAIClient\n",
        "import os\n",
        "\n",
        "class CourseRecommendationTool(Tool):\n",
        "    name: str = \"ARES Course Recommender\"\n",
        "    description: str = \"Uses ARES-style reasoning to retrieve and rank the top 5 online courses (free and paid) on a given topic.\"\n",
        "    action_type: str = \"recommend_courses_with_ares\"\n",
        "    input_format: str = \"A topic string like 'data science' or 'web development'.\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.llm = OpenAIClient(\n",
        "            api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
        "            model_name=\"gpt-4o\"  # ✅ fixed param\n",
        "        )\n",
        "\n",
        "    def run(self, input_text: Any) -> str:\n",
        "        topic = input_text.strip()\n",
        "        \n",
        "        try:\n",
        "            # Step 1: Simulate Retrieval Phase\n",
        "            retrieval_prompt = (\n",
        "                f\"List 8-10 popular free and paid online courses for the topic '{topic}'. \"\n",
        "                f\"Include title, platform, type (free/paid), and estimated quality.\"\n",
        "            )\n",
        "            retrieval_response = self.llm.chat_completion(\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"You retrieve raw course data from across the web.\"},\n",
        "                    {\"role\": \"user\", \"content\": retrieval_prompt}\n",
        "                ]\n",
        "            )\n",
        "            raw_courses = retrieval_response.choices[0].message[\"content\"]\n",
        "\n",
        "            # Step 2: Simulate Reasoning/Ranking Phase\n",
        "            ranking_prompt = (\n",
        "                f\"From the following raw course list, pick the **top 5 most valuable** courses \"\n",
        "                f\"(balanced between free and paid) for a beginner interested in '{topic}'. \"\n",
        "                f\"Rank them in markdown with links if available:\\n\\n{raw_courses}\"\n",
        "            )\n",
        "            ranking_response = self.llm.chat_completion(\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"You are an expert course reviewer ranking options for users.\"},\n",
        "                    {\"role\": \"user\", \"content\": ranking_prompt}\n",
        "                ]\n",
        "            )\n",
        "\n",
        "            return ranking_response.choices[0].message[\"content\"]\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"⚠️ ARES-style reasoning failed: {str(e)}\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YHUz6e8ZzPl"
      },
      "source": [
        "## Step 5: Pass tool to AgentPro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47wUizrrVPTr",
        "outputId": "02806366-6c79-4de7-cff2-71b7314ac7ad"
      },
      "outputs": [],
      "source": [
        "# Instantiate your tools and ReactAgent\n",
        "tools = [MostModelTool()]\n",
        "\n",
        "# Create a model with OpenAI\n",
        "model = create_model(provider=\"openai\", model_name=\"gpt-4o\", api_key=os.getenv(\"OPENAI_API_KEY\", None))\n",
        "\n",
        "myagent = ReactAgent(model=model, tools=tools)\n",
        "\n",
        "# Run\n",
        "query = \"Can you give me the name of the model that has the most downloads in the 'text-classification' task on the Hugging Face Hub?\"\n",
        "response = myagent.run(query)\n",
        "# Can you give me the name of the model that has the most downloads in the 'text-classification' task on the Hugging Face Hub?\n",
        "# Find the most popular model used for 'object-detection' on Hugging Face.\n",
        "\n",
        "print(f\"\\nFinal Answer: {response.final_answer}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "\"CourseRecommendationTool\" object has no field \"llm\"",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Load tools\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m tools = [\u001b[43mCourseRecommendationTool\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Create model\u001b[39;00m\n\u001b[32m     11\u001b[39m model = create_model(\n\u001b[32m     12\u001b[39m     provider=\u001b[33m\"\u001b[39m\u001b[33mopenai\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     13\u001b[39m     model_name=\u001b[33m\"\u001b[39m\u001b[33mgpt-4o\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     14\u001b[39m     api_key=os.getenv(\u001b[33m\"\u001b[39m\u001b[33mOPENAI_API_KEY\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     15\u001b[39m )\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mCourseRecommendationTool.__init__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m     15\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m()\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mllm\u001b[49m = OpenAIClient(\n\u001b[32m     17\u001b[39m         api_key=os.getenv(\u001b[33m\"\u001b[39m\u001b[33mOPENAI_API_KEY\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     18\u001b[39m         model_name=\u001b[33m\"\u001b[39m\u001b[33mgpt-4o\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# ✅ fixed param\u001b[39;00m\n\u001b[32m     19\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\washa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pydantic\\main.py:997\u001b[39m, in \u001b[36mBaseModel.__setattr__\u001b[39m\u001b[34m(self, name, value)\u001b[39m\n\u001b[32m    995\u001b[39m     setattr_handler(\u001b[38;5;28mself\u001b[39m, name, value)\n\u001b[32m    996\u001b[39m \u001b[38;5;66;03m# if None is returned from _setattr_handler, the attribute was set directly\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m997\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m (setattr_handler := \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_setattr_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    998\u001b[39m     setattr_handler(\u001b[38;5;28mself\u001b[39m, name, value)  \u001b[38;5;66;03m# call here to not memo on possibly unknown fields\u001b[39;00m\n\u001b[32m    999\u001b[39m     \u001b[38;5;28mself\u001b[39m.__pydantic_setattr_handlers__[name] = setattr_handler\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\washa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pydantic\\main.py:1044\u001b[39m, in \u001b[36mBaseModel._setattr_handler\u001b[39m\u001b[34m(self, name, value)\u001b[39m\n\u001b[32m   1041\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.__pydantic_fields__:\n\u001b[32m   1042\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.model_config.get(\u001b[33m'\u001b[39m\u001b[33mextra\u001b[39m\u001b[33m'\u001b[39m) != \u001b[33m'\u001b[39m\u001b[33mallow\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m   1043\u001b[39m         \u001b[38;5;66;03m# TODO - matching error\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1044\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m object has no field \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m   1045\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m attr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1046\u001b[39m         \u001b[38;5;66;03m# attribute does not exist, so put it in extra\u001b[39;00m\n\u001b[32m   1047\u001b[39m         \u001b[38;5;28mself\u001b[39m.__pydantic_extra__[name] = value\n",
            "\u001b[31mValueError\u001b[39m: \"CourseRecommendationTool\" object has no field \"llm\""
          ]
        }
      ],
      "source": [
        "# main.py or streamlit_app.py\n",
        "\n",
        "#from custom_tools.course_tool import CourseRecommendationTool\n",
        "from agentpro import ReactAgent, create_model\n",
        "import os\n",
        "\n",
        "# Load tools\n",
        "tools = [CourseRecommendationTool()]\n",
        "\n",
        "# Create model\n",
        "model = create_model(\n",
        "    provider=\"openai\",\n",
        "    model_name=\"gpt-4o\",\n",
        "    api_key=os.getenv(\"OPENAI_API_KEY\")\n",
        ")\n",
        "\n",
        "# Create agent\n",
        "agent = ReactAgent(model=model, tools=tools)\n",
        "\n",
        "# Run query\n",
        "query = \"Recommend the best online courses for learning AI in 2025\"\n",
        "response = agent.run(query)\n",
        "\n",
        "# Output\n",
        "print(\"\\nFinal Answer:\\n\", response.final_answer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pf8Y3xCcWhyl"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
